---
layout: page
title:  Qi She (ä½˜çª)
date:   2020-12-14 21:03:36 +0530
description: "Qi She (ä½˜çª) is a Research Scientist at ByteDance leading the Applied Algorithm & Foundationteam in Business Integrity. Expert in Multimodal LLMs, Agentic AI, Machine Learning, Computer Vision, and Robotics."
keywords: "Qi She, ä½˜çª, ByteDance, Applied Algorithm, Agentic AI, Multimodal Large Language Model, Machine Learning, Computer Vision, AI, Research Scientist, Intel Labs"
---

### **About / å…³äºæˆ‘**
Qi She (ä½˜çª) leads the Applied Algorithm & Foundation team at ByteDance Business Integrity, where he spearheads the large-scale industrialization of **Multimodal Large Language Models (MLLMs)** and **Agentic Foundation** capabilities. Since 2023, his work has focused on the end-to-end deployment of AI Agents.

A 2018 Ph.D. graduate from City University of Hong Kong and a former visiting scholar at Princeton, Qi was honored with the 2025 CityU **Young Alumni Award** for his professional excellence. Previously, as a Research Scientist at Intel Labs, he received the 2020 Intel **Gordy Award**â€”the lab's highest honor named after Gordon Moore. His long-term research in Generative Models and Representation Learning has been extensively published in premier venues including **TPAMI, NeurIPS, ICLRï¼ŒICML, CVPR, and ICCV**.

### **Recent Focus / å·¥ä½œæ–¹å‘**
Focusing on the industrial-scale deployment of Agentic AI within ByteDanceâ€™s Business Integrity ecosystem:
- **Architecting Agentic Foundations**: Developing specialized (M)LLMs optimized for reasoning, planning, and autonomous decision-making in high-stakes security scenarios.
- **Scaling Autonomous Agents**: Leading the end-to-end integration of Multi-Agent systems to handle massive real-time traffic, ensuring robustness and alignment with evolving safety policies.
- **Advancing MLLM-Agent Synergy**: Pioneering the fusion of (M)LLMs with agentic workflows to solve complex, fine-grained content understanding challenges at scale.

[**<font color="#dd0000">Hiring!</font>**] Recruiting scientists, engineers, and research/engineering interns in Multi Modal Large Language Model & Agentic AI Fooundation at Beijing, Shanghai, Singapore and San Joseï½ Feel free to [**contact me**](mailto:sheqi.roger@bytedance.com) . å’Œä¼˜ç§€äººæ‰ä¸€èµ·æ¢ç´¢å¹¶è½åœ°å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œåœ¨ä¸šåŠ¡åœºæ™¯åšæ·±åº¦é€‚é…å’Œæè‡´ä¼˜åŒ–ï¼Œå¯»æ‰¾å…·å¤‡å‡ºè‰²é—®é¢˜åˆ†æä¸è§£å†³èƒ½åŠ›çš„å€™é€‰äºº:
- [æ­£å¼] å¤šæ¨¡æ€å¤§æ¨¡å‹ç®—æ³•å·¥ç¨‹å¸ˆ/åº”ç”¨ç ”ç©¶å‘˜ï¼ˆSFT/RM/RLHF/Pretrain, Agentæ¡†æ¶+åº”ç”¨ï¼‰æ‹›è˜ä¸­
- [å®ä¹ ] å¤šæ¨¡æ€å¤§æ¨¡å‹ã€è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰ã€Œç®—æ³•ç ”ç©¶å®ä¹ ç”Ÿã€æ‹›è˜ä¸­

### **News / åŠ¨æ€**
- Selected recent news and activities since 2020.

<div class="news-list">
  <h4 class="news-year">2024</h4>
  <ul>
    <li><span class="news-date">2024-02</span> ğŸ“¢ Invited as a reviewer for <b>ICML 2024</b>.</li>
  </ul>

  <h4 class="news-year">2023</h4>
  <ul>
    <li><span class="news-date">2023-08-25</span> ğŸ“¢ Invited as a reviewer for <b>ICLR 2024</b>.</li>
    <li><span class="news-date">2023-08-01</span> ğŸ“„ Our work "Background-aware Classification Activation Map for Weakly Supervised Object Localization" is accepted into <b>IEEE TPAMI 2023</b>.</li>
    <li><span class="news-date">2023-03-28</span> ğŸ“¢ Invited as a reviewer for <b>NeurIPS 2023</b>.</li>
    <li><span class="news-date">2023-01-29</span> ğŸ“¢ Invited as a reviewer for <b>ICML 2023</b>.</li>
  </ul>

  <h4 class="news-year">2022</h4>
  <ul>
    <li><span class="news-date">2022-11-02</span> ğŸ“¢ Invited as a reviewer for <b>CVPR 2023</b>.</li>
    <li><span class="news-date">2022-07-30</span> ğŸ“¢ Invited as a reviewer for <b>ICLR 2023</b>.</li>
    <li><span class="news-date">2022-05-15</span> ğŸ“„ Our work "PDO-e3DCNNs" is accepted into <b>ICML 2022</b>.</li>
    <li><span class="news-date">2022-03-03</span> ğŸ“„ We have <b>3</b> papers accepted into <b>CVPR 2022</b>.</li>
    <li><span class="news-date">2022-02-16</span> ğŸ“„ "Newton Design: Designing CNNs with the Family of Newton's Methods" is accepted into <b>Science China (Information Sciences)</b>.</li>
  </ul>

  <h4 class="news-year">2021</h4>
  <ul>
    <li><span class="news-date">2021-07-24</span> ğŸ“„ We have <b>3</b> papers accepted into <b>ICCV 2021</b>.</li>
    <li><span class="news-date">2021-07-23</span> ğŸ“¢ Invited as a reviewer for <b>ACM MM 2021</b> industrial track.</li>
    <li><span class="news-date">2021-06-13</span> ğŸ“¢ Invited as a reviewer for <b>ICLR 2022</b>.</li>
    <li><span class="news-date">2021-04-12</span> ğŸ“„ "An Efficient and Flexible Spike Train Model via Empirical Bayes" is accepted into <b>IEEE TSP</b>.</li>
    <li><span class="news-date">2021-04-06</span> ğŸ“¢ Invited as a reviewer for <b>NeurIPS 2021</b>.</li>
    <li><span class="news-date">2021-03-04</span> ğŸ“„ We have <b>3</b> papers accepted into <b>CVPR 2021</b>.</li>
  </ul>

  <h4 class="news-year">2020</h4>
  <ul>
    <li><span class="news-date">2020-12-14</span> ğŸ“¢ Workshop proposal "Continual Learning in Computer Vision" is accepted by <b>CVPR 2021</b> (selected from 109 proposals).</li>
    <li><span class="news-date">2020-12-09</span> ğŸ“¢ Invited as an <b>expert reviewer</b> for <b>ICML 2021</b>.</li>
    <li><span class="news-date">2020-11-24</span> ğŸ“„ Our survey "Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy" is accepted by <b>ACM Computing Surveys</b>.</li>
    <li><span class="news-date">2020-08-14</span> ğŸ“¢ Joined <b>ByteDance AI Lab</b> as a Research Scientist.</li>
  </ul>
</div>


<details>
  <summary>Older News / æ›´æ—©çš„åŠ¨æ€ï¼ˆ2016â€“2020ï¼‰</summary>
  <div class="news-list">
  <ul>
    <li><span class="news-date">2020-06-14</span> ğŸ“¢ We have successfully organized the 1st "Continual Learning in Computer Vision" workshop at <b>CVPR 2020</b>.</li>
    <li><span class="news-date">2020-06-10</span> ğŸ“„ Our paper "IROS 2019 Lifelong Robotic Vision: Object Recognition Challenge [Competitions]" has been published at IEEE Robotics & Automation Magazine (IEEE RAM). The journal is one of four top-tier journals in robotics field.</li>
    <li><span class="news-date">2020-06-01</span> ğŸ“„ Our paper is accepted as the <b>Oral</b> presentation at the conference of Uncertainty in Artificial Intelligence (UAI).</li>
    <li><span class="news-date">2020-05-22</span> ğŸ“„ Our paper "Synthetic-Neuroscore: Using a neuro-AI interface for evaluating generative adversarial networks" has been accepted by <b>Neurocomputing</b>.</li>
    <li><span class="news-date">2020-01-22</span> ğŸ“„ We have <b>2</b> papers regarding <b>lifelong robotic vision</b> accepted by <b>ICRA 2020</b>.</li>
  </ul>
  </div>
</details>


<!--
## **Outcomes**
- In general, until 2023/10, I hold **2100 citations** from Google Sholar, with **h index: 19, i10 index 25**ï¼Œpublishing at TPAMI, TNNLS, TSP, CSUR, Nature Scientific Reports, ICML, CVPR, ICCV, ICLR, AAAI etc; and holding **5** US patents, and **20+** China patents.
- At byetedance, I launched several ranking models/computer vision solutions as baselines; and at Intel Labs, I am the first contributor of [Lifelong Robotic Vision].
-->

## **ğŸ† Awards / å¥–é¡¹**
<div class="news-list">
  <ul>
    <li><span class="news-date">2024-03</span> ByteDance Monetization Product and Technology Q4 Inspire Award (<b>å›¢é˜Ÿå¥–</b>).</li>
    <li><span class="news-date">2023-09</span> ByteDance Monetization Product and Technology Q2 Inspire Award (<b>å›¢é˜Ÿå¥–</b>).</li>
    <li><span class="news-date">2021</span> 3rd Place (3/383) in Google Landmark Recognition 2021, the kaggle competition.</li>
    <li><span class="news-date">2020</span> Recognized as <b>top 10%</b> high-scoring reviewer at <b>NeurIPS 2020</b>.</li>
    <li><span class="news-date">2020</span> Annual Intel Labs Gordy Awards (the highest annual research award named after Intelâ€™s co-founder Gordon Earle Moore, <b>æˆˆç™»Â·æ‘©å°”å¥–</b>, famous for <b>æ‘©å°”å®šå¾‹</b>).</li>
    <li><span class="news-date">2018-2020</span> 5 times Intel China Awards (2018 Q4ã€2019 Q1ã€2019 Q3ã€2020 Q1ã€& 2020 Q2).</li>
    <li><span class="news-date">2016</span> 2nd place in the <a href="https://www.youtube.com/watch?v=u0RCcuZpmxg">10th Global Artificial Intelligence Hackathon</a> by Korea ministry of ICT.</li>
    <li><span class="news-date">2016</span> Outstanding Academic Performance Award.</li>
  </ul>
</div>

[ACM Computing Surveys]: https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=19
[CLVISION]: https://sites.google.com/view/clvision2020/overview?authuser=0
[GAN Survey]:https://arxiv.org/abs/1906.01529
[IEEE RAM]: https://ieeexplore.ieee.org/document/9113359
[AI hackathon]: https://www.youtube.com/watch?v=u0RCcuZpmxg
[Lifelong Robotic Vision]: https://lifelong-robotic-vision.github.io/

<div class="analytics">
	{% include clastrmap.html %}
</div>
