---
layout: page
title:  Qi She (佘琪)
date:   2020-12-14 21:03:36 +0530
---

### **About / 关于我**
Qi She (佘琪) is leading the Applied Algorithm team in Business Integrity at ByteDance, focusing on multimodal Large Language Models, Machine Learning and Computer Vision in real-world AI products. Previously, he was a Research Scientist at Intel Labs, working on statistical machine learning, deep learning and lifelong robotic vision.

### **Recent Focus / 当前工作方向**
I am currently leading Applied Algorithm team in Business Integrity at ByteDance, focusing on applying (Multi Modal) Large Language Model、Machine Learning and Computer Vision techniques in AI products. Before that, I was a research scientist at Intel Labs.

[**<font color="#dd0000">Hiring!</font>**] Recruiting scientists, engineers, and research/engineering interns in Multi Modal Large Language Model at Beijing, Shanghai and Hangzhou ～ Feel free to [**contact me**](mailto:sheqi.roger@bytedance.com) . 和优秀人才一起探索并落地多模态大模型，在业务场景做深度适配和极致优化，寻找具备出色问题分析与解决能力的候选人:
- [正式] 多模态大模型算法工程师/应用研究员（SFT/RM/RLHF/Pretrain, Agent框架+应用）招聘中
- [实习] 多模态大模型、计算机视觉、自然语言处理等「算法研究实习生」招聘中

### **News / 动态**
- Selected recent news and activities since 2020.

<div class="news-list">
  <h4 class="news-year">2024</h4>
  <ul>
    <li><span class="news-date">2024-03</span> <span class="news-tag news-tag-award">Award</span> Received Bytedance Monetization Product and Technology Q4 Inspire Award (<b>团队奖</b>).</li>
    <li><span class="news-date">2024-02</span> Invited as a reviewer for <b>ICML 2024</b>.</li>
  </ul>

  <h4 class="news-year">2023</h4>
  <ul>
    <li><span class="news-date">2023-09</span> <span class="news-tag news-tag-award">Award</span> Received Bytedance Monetization Product and Technology Q2 Inspire Award (<b>团队奖</b>).</li>
    <li><span class="news-date">2023-08-25</span> <span class="news-tag news-tag-reviewer">Reviewer</span> Invited as a reviewer for <b>ICLR 2024</b>.</li>
    <li><span class="news-date">2023-08-01</span> <span class="news-tag news-tag-paper">Paper</span> Our work "Background-aware Classification Activation Map for Weakly Supervised Object Localization" is accepted into <b>IEEE TPAMI 2023</b>.</li>
    <li><span class="news-date">2023-03-28</span> <span class="news-tag news-tag-reviewer">Reviewer</span> Invited as a reviewer for <b>NeurIPS 2023</b>.</li>
    <li><span class="news-date">2023-01-29</span> <span class="news-tag news-tag-reviewer">Reviewer</span> Invited as a reviewer for <b>ICML 2023</b>.</li>
  </ul>

  <h4 class="news-year">2022</h4>
  <ul>
    <li><span class="news-date">2022-11-02</span> <span class="news-tag news-tag-reviewer">Reviewer</span> Invited as a reviewer for <b>CVPR 2023</b>.</li>
    <li><span class="news-date">2022-07-30</span> <span class="news-tag news-tag-reviewer">Reviewer</span> Invited as a reviewer for <b>ICLR 2023</b>.</li>
    <li><span class="news-date">2022-05-15</span> <span class="news-tag news-tag-paper">Paper</span> Our work "PDO-e3DCNNs" is accepted into <b>ICML 2022</b>.</li>
    <li><span class="news-date">2022-03-03</span> <span class="news-tag news-tag-paper">Paper</span> We have <b>3</b> papers accepted into <b>CVPR 2022</b>.</li>
    <li><span class="news-date">2022-02-16</span> <span class="news-tag news-tag-paper">Paper</span> "Newton Design: Designing CNNs with the Family of Newton's Methods" is accepted into <b>Science China (Information Sciences)</b>.</li>
  </ul>

  <h4 class="news-year">2021</h4>
  <ul>
    <li><span class="news-date">2021-07-24</span> <span class="news-tag news-tag-paper">Paper</span> We have <b>3</b> papers accepted into <b>ICCV 2021</b>.</li>
    <li><span class="news-date">2021-07-23</span> <span class="news-tag news-tag-reviewer">Reviewer</span> Invited as a reviewer for <b>ACM MM 2021</b> industrial track.</li>
    <li><span class="news-date">2021-06-13</span> <span class="news-tag news-tag-reviewer">Reviewer</span> Invited as a reviewer for <b>ICLR 2022</b>.</li>
    <li><span class="news-date">2021-04-12</span> <span class="news-tag news-tag-paper">Paper</span> "An Efficient and Flexible Spike Train Model via Empirical Bayes" is accepted into <b>IEEE TSP</b>.</li>
    <li><span class="news-date">2021-04-06</span> <span class="news-tag news-tag-reviewer">Reviewer</span> Invited as a reviewer for <b>NeurIPS 2021</b>.</li>
    <li><span class="news-date">2021-03-04</span> <span class="news-tag news-tag-paper">Paper</span> We have <b>3</b> papers accepted into <b>CVPR 2021</b>.</li>
  </ul>

  <h4 class="news-year">2020</h4>
  <ul>
    <li><span class="news-date">2020-12-14</span> Workshop proposal "Continual Learning in Computer Vision" is accepted by <b>CVPR 2021</b> (selected from 109 proposals).</li>
    <li><span class="news-date">2020-12-09</span> <span class="news-tag news-tag-reviewer">Reviewer</span> Invited as an <b>expert reviewer</b> for <b>ICML 2021</b>.</li>
    <li><span class="news-date">2020-11-24</span> <span class="news-tag news-tag-paper">Paper</span> Our survey "Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy" is accepted by <b>ACM Computing Surveys</b>.</li>
    <li><span class="news-date">2020-10-21</span> <span class="news-tag news-tag-award">Award</span> Recognized as <b>top 10%</b> high-scoring reviewer at <b>NeurIPS 2020</b>.</li>
    <li><span class="news-date">2020-08-14</span> Joined <b>ByteDance AI Lab</b> as a Research Scientist.</li>
  </ul>
</div>


<details>
  <summary>Older News / 更早的动态（2016–2020）</summary>
  <ul>
    <li>[2020-06-14] We have successfully organized the 1st "Continual Learning in Computer Vision" workshop at <b>CVPR 2020</b>.</li>
    <li>[2020-06-10] [<b><font color="#dd0000">Paper</font></b>] Our paper "IROS 2019 Lifelong Robotic Vision: Object Recognition Challenge [Competitions]" has been published at IEEE Robotics & Automation Magazine (IEEE RAM). The journal is one of four top-tier journals in robotics field.</li>
    <li>[2020-06-01] [<b><font color="#dd0000">Paper</font></b>] Our paper is accepted as the <b>Oral</b> presentation at the conference of Uncertainty in Artificial Intelligence (UAI).</li>
    <li>[2020-05-22] [<b><font color="#dd0000">Paper</font></b>] Our paper "Synthetic-Neuroscore: Using a neuro-AI interface for evaluating generative adversarial networks" has been accepted by <b>Neurocomputing</b>.</li>
    <li>[2020-01-22] [<b><font color="#dd0000">Paper</font></b>] We have <b>2</b> papers regarding <b>lifelong robotic vision</b> accepted by <b>ICRA 2020</b>.</li>
  </ul>
</details>


<!--
## **Outcomes**
- In general, until 2023/10, I hold **2100 citations** from Google Sholar, with **h index: 19, i10 index 25**，publishing at TPAMI, TNNLS, TSP, CSUR, Nature Scientific Reports, ICML, CVPR, ICCV, ICLR, AAAI etc; and holding **5** US patents, and **20+** China patents.
- At byetedance, I launched several ranking models/computer vision solutions as baselines; and at Intel Labs, I am the first contributor of [Lifelong Robotic Vision].
-->

## **Awards / 奖项**
- Bytedance Monetization Product and Technolog Q2/Q4 Inspire Award (<b>团队奖</b>), Sept. 2023 & March. 2024
- 3rd Place (3/383) in Google Landmark Recognition 2021, the kaggle competition
- 5 times Intel China Awards, 2018 Q4、2019 Q1、2019 Q3、2020 Q1、& 2020 Q2
- Annual Intel Labs Gordy Awards (the highest annual research award named after Intel’s co-founder Gordon Earle Moore, <b>戈登·摩尔奖</b>, famous for <b>摩尔定律</b>), 2020
- 2nd place in the [10th Global Artificial Intelligence Hackathon][AI hackathon] by Korea ministry of ICT, 2016
- Outstanding Academic Performance Award, 2016

[ACM Computing Surveys]: https://www.letpub.com.cn/index.php?page=journalapp&view=detail&journalid=19
[CLVISION]: https://sites.google.com/view/clvision2020/overview?authuser=0
[GAN Survey]:https://arxiv.org/abs/1906.01529
[IEEE RAM]: https://ieeexplore.ieee.org/document/9113359
[AI hackathon]: https://www.youtube.com/watch?v=u0RCcuZpmxg
[Lifelong Robotic Vision]: https://lifelong-robotic-vision.github.io/

<div class="analytics">
	{% include clastrmap.html %}
</div>